{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2547dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install -r requirements.txt\n",
    "#%pip install huggingface_hub\n",
    "#%pip install transformers torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85fdac6d",
   "metadata": {},
   "source": [
    "Existem 5 tipos diferentes de mensagens:\n",
    "\n",
    "- `HumanMessage`: Isso representa uma mensagem do usuário. Geralmente consiste apenas de conteúdo.\n",
    "\n",
    "- `AIMessage`: Isso representa uma mensagem do modelo. Pode ter additional_kwargs incluídos - por exemplo, tool_calls se estiver usando chamadas de ferramentas da OpenAI.\n",
    "\n",
    "- `SystemMessage`: Isso representa uma mensagem do sistema, que indica ao modelo como se comportar. Geralmente consiste apenas de conteúdo. Nem todo modelo suporta isso.\n",
    "\n",
    "- `FunctionMessage`: Isso representa o resultado de uma chamada de função. Além do papel e conteúdo, esta mensagem tem um parâmetro de nome que transmite o nome da função que foi chamada para produzir este resultado.\n",
    "\n",
    "- `ToolMessage`: Isso representa o resultado de uma chamada de ferramenta. Isso é distinto de uma Mensagem de Função a fim de corresponder aos tipos de mensagens de função e ferramenta da OpenAI. Além do papel e conteúdo, esta mensagem tem um parâmetro tool_call_id que transmite o id da chamada à ferramenta que foi feita para produzir este resultado."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec0a7f7",
   "metadata": {},
   "source": [
    "### Importação da API do Gemini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb1a8b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage\n",
    "from langchain_community.chat_models.huggingface import ChatHuggingFace\n",
    "from langchain_community.llms.huggingface_endpoint import HuggingFaceEndpoint\n",
    "from langchain_openai import OpenAI\n",
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba79cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"GOOGLE_API_KEY\" not in os.environ:\n",
    "    os.environ[\"GOOGLE_API_KEY\"] = getpass.getpass(\"Enter your Google AI API key: \")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "728ab20b",
   "metadata": {},
   "source": [
    "### Configuração modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d54042f",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce45c39",
   "metadata": {},
   "source": [
    "### Teste de configuração do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c78406d",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    (\"system\", \"Você é um assistente que traduz do inglês para o francês. Traduza o seguinte.\"),\n",
    "    (\"human\", \"I love programming.\")\n",
    "]\n",
    "ai_msg = llm.invoke(messages)\n",
    "print(ai_msg.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29fc4282",
   "metadata": {},
   "source": [
    "### Chamadas simultâneas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdfe38b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "perguntas = [\n",
    "\t'O que é o céu?',\n",
    "\t'O que é o mar?',\n",
    "\t'Como podemos ver as estrelas?'\n",
    "]\n",
    "\n",
    "llm.batch(perguntas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f73e3b5f",
   "metadata": {},
   "source": [
    "### Chat Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61bdfd26",
   "metadata": {},
   "outputs": [],
   "source": [
    "mensagens = [\n",
    "\tSystemMessage(content='Você é um assistente que conta piadas.'),\n",
    "\tHumanMessage(content='Conte uma piada de um velho português')\n",
    "]\n",
    "llm.invoke(mensagens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "455a0b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Conteúdo da mensagem\n",
    "print(llm.invoke(mensagens).content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164bb923",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Metadados da mensagem\n",
    "print(llm.invoke(mensagens).response_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cabf230c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Uma maneira mais interessante de mostrar o conteúdo do chat\n",
    "mensagens = [\n",
    "\tSystemMessage(content='Você é um assistente que conta piadas.'),\n",
    "\tHumanMessage(content='Conte uma piada de um velho português')\n",
    "]\n",
    "for trecho in llm.stream(mensagens):\n",
    "\tprint(trecho.content, end='')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e89a1cf6",
   "metadata": {},
   "source": [
    "### Prompt few-shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5398b0fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "mensagens = [\n",
    "\tHumanMessage(content='Quando é 1 + 1?'),\n",
    "\tAIMessage(content='2'),\n",
    "\tHumanMessage(content='Quando é 10 * 5?'),\n",
    "\tAIMessage(content='50'),\n",
    "\tHumanMessage(content='Quando é 10 + 3?'),\n",
    "]\n",
    "\n",
    "print(llm.invoke(mensagens).content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c6f486",
   "metadata": {},
   "source": [
    "### Utilização de outros modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffaf9f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.getenv(\"HUGGINGFACEHUB_API_TOKEN\"):\n",
    "    os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = getpass.getpass(\"Enter your token: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "377f7e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo = 'mistralai/Mixtral-8x7B-Instruct-v0.1'\n",
    "llm = HuggingFaceEndpoint(repo_id=modelo)\n",
    "chat = ChatHuggingFace(llm=llm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39fd06c4",
   "metadata": {},
   "source": [
    "### Debugando as LLMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b56d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain\n",
    "langchain.debug = True\n",
    "llm.invoke(mensagens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fa8ce4e",
   "metadata": {},
   "source": [
    "### Caching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153add86",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = ChatOpenAI (model='gpt-3.5-turbo-0125')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fe6b3add",
   "metadata": {},
   "outputs": [],
   "source": [
    "mensagens = [\n",
    "\tSystemMessage(content='Você um especialista em matemática.'),\n",
    "\tHumanMessage(content='Quanto é a soma de 1 + 1?')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "22fa7694",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.cache import InMemoryCache\n",
    "from langchain.globals import set_llm_cache\n",
    "\n",
    "set_llm_cache(InMemoryCache())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "16548bd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"System: Você um especialista em matemática.\\nHuman: Quanto é a soma de 1 + 1?\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[llm:ChatOpenAI] [3.39s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\",\n",
      "          \"logprobs\": null\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"A soma de 1 + 1 é igual a 2.\",\n",
      "            \"additional_kwargs\": {\n",
      "              \"refusal\": null\n",
      "            },\n",
      "            \"response_metadata\": {\n",
      "              \"token_usage\": {\n",
      "                \"completion_tokens\": 14,\n",
      "                \"prompt_tokens\": 32,\n",
      "                \"total_tokens\": 46,\n",
      "                \"completion_tokens_details\": {\n",
      "                  \"accepted_prediction_tokens\": 0,\n",
      "                  \"audio_tokens\": 0,\n",
      "                  \"reasoning_tokens\": 0,\n",
      "                  \"rejected_prediction_tokens\": 0\n",
      "                },\n",
      "                \"prompt_tokens_details\": {\n",
      "                  \"audio_tokens\": 0,\n",
      "                  \"cached_tokens\": 0\n",
      "                }\n",
      "              },\n",
      "              \"model_name\": \"gpt-3.5-turbo-0125\",\n",
      "              \"system_fingerprint\": null,\n",
      "              \"finish_reason\": \"stop\",\n",
      "              \"logprobs\": null\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run--a6afb917-2c84-444a-91c8-7a6ee61b6555-0\",\n",
      "            \"usage_metadata\": {\n",
      "              \"input_tokens\": 32,\n",
      "              \"output_tokens\": 14,\n",
      "              \"total_tokens\": 46,\n",
      "              \"input_token_details\": {\n",
      "                \"audio\": 0,\n",
      "                \"cache_read\": 0\n",
      "              },\n",
      "              \"output_token_details\": {\n",
      "                \"audio\": 0,\n",
      "                \"reasoning\": 0\n",
      "              }\n",
      "            },\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        },\n",
      "        \"text\": \"A soma de 1 + 1 é igual a 2.\"\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"completion_tokens\": 14,\n",
      "      \"prompt_tokens\": 32,\n",
      "      \"total_tokens\": 46,\n",
      "      \"completion_tokens_details\": {\n",
      "        \"accepted_prediction_tokens\": 0,\n",
      "        \"audio_tokens\": 0,\n",
      "        \"reasoning_tokens\": 0,\n",
      "        \"rejected_prediction_tokens\": 0\n",
      "      },\n",
      "      \"prompt_tokens_details\": {\n",
      "        \"audio_tokens\": 0,\n",
      "        \"cached_tokens\": 0\n",
      "      }\n",
      "    },\n",
      "    \"model_name\": \"gpt-3.5-turbo-0125\",\n",
      "    \"system_fingerprint\": null\n",
      "  },\n",
      "  \"run\": null,\n",
      "  \"type\": \"LLMResult\"\n",
      "}\n",
      "CPU times: total: 15.6 ms\n",
      "Wall time: 3.39 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='A soma de 1 + 1 é igual a 2.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 32, 'total_tokens': 46, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run--a6afb917-2c84-444a-91c8-7a6ee61b6555-0', usage_metadata={'input_tokens': 32, 'output_tokens': 14, 'total_tokens': 46, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Executando pela primeira vez.\n",
    "%%time\n",
    "chat.invoke(mensagens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c1a5c50d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"System: Você um especialista em matemática.\\nHuman: Quanto é a soma de 1 + 1?\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[llm:ChatOpenAI] [1ms] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\",\n",
      "          \"logprobs\": null\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"A soma de 1 + 1 é igual a 2.\",\n",
      "            \"additional_kwargs\": {\n",
      "              \"refusal\": null\n",
      "            },\n",
      "            \"response_metadata\": {\n",
      "              \"token_usage\": {\n",
      "                \"completion_tokens\": 14,\n",
      "                \"prompt_tokens\": 32,\n",
      "                \"total_tokens\": 46,\n",
      "                \"completion_tokens_details\": {\n",
      "                  \"accepted_prediction_tokens\": 0,\n",
      "                  \"audio_tokens\": 0,\n",
      "                  \"reasoning_tokens\": 0,\n",
      "                  \"rejected_prediction_tokens\": 0\n",
      "                },\n",
      "                \"prompt_tokens_details\": {\n",
      "                  \"audio_tokens\": 0,\n",
      "                  \"cached_tokens\": 0\n",
      "                }\n",
      "              },\n",
      "              \"model_name\": \"gpt-3.5-turbo-0125\",\n",
      "              \"system_fingerprint\": null,\n",
      "              \"finish_reason\": \"stop\",\n",
      "              \"logprobs\": null\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run--a6afb917-2c84-444a-91c8-7a6ee61b6555-0\",\n",
      "            \"usage_metadata\": {\n",
      "              \"input_tokens\": 32,\n",
      "              \"output_tokens\": 14,\n",
      "              \"total_tokens\": 46,\n",
      "              \"input_token_details\": {\n",
      "                \"audio\": 0,\n",
      "                \"cache_read\": 0\n",
      "              },\n",
      "              \"output_token_details\": {\n",
      "                \"audio\": 0,\n",
      "                \"reasoning\": 0\n",
      "              }\n",
      "            },\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        },\n",
      "        \"text\": \"A soma de 1 + 1 é igual a 2.\"\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null,\n",
      "  \"type\": \"LLMResult\"\n",
      "}\n",
      "CPU times: total: 0 ns\n",
      "Wall time: 2.21 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='A soma de 1 + 1 é igual a 2.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 32, 'total_tokens': 46, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run--a6afb917-2c84-444a-91c8-7a6ee61b6555-0', usage_metadata={'input_tokens': 32, 'output_tokens': 14, 'total_tokens': 46, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Executando pela segunda vez, com o cache ativado.\n",
    "%%time\n",
    "chat.invoke(mensagens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b324a52a",
   "metadata": {},
   "source": [
    "### Cache usando SQLite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f96e0dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.cache import SQLiteCache\n",
    "from langchain.globals import set_llm_cache\n",
    "\n",
    "set_llm_cache(SQLiteCache(database_path='./arquivos/langchain_cache_db.sqlite'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "941aa8a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"System: Você um especialista em matemática.\\nHuman: Quanto é a soma de 1 + 1?\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[llm:ChatOpenAI] [2.20s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\",\n",
      "          \"logprobs\": null\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"A soma de 1 + 1 é igual a 2.\",\n",
      "            \"additional_kwargs\": {\n",
      "              \"refusal\": null\n",
      "            },\n",
      "            \"response_metadata\": {\n",
      "              \"token_usage\": {\n",
      "                \"completion_tokens\": 14,\n",
      "                \"prompt_tokens\": 32,\n",
      "                \"total_tokens\": 46,\n",
      "                \"completion_tokens_details\": {\n",
      "                  \"accepted_prediction_tokens\": 0,\n",
      "                  \"audio_tokens\": 0,\n",
      "                  \"reasoning_tokens\": 0,\n",
      "                  \"rejected_prediction_tokens\": 0\n",
      "                },\n",
      "                \"prompt_tokens_details\": {\n",
      "                  \"audio_tokens\": 0,\n",
      "                  \"cached_tokens\": 0\n",
      "                }\n",
      "              },\n",
      "              \"model_name\": \"gpt-3.5-turbo-0125\",\n",
      "              \"system_fingerprint\": null,\n",
      "              \"finish_reason\": \"stop\",\n",
      "              \"logprobs\": null\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run--b0075ab6-f081-4aec-b88d-d7b3dfc9cca6-0\",\n",
      "            \"usage_metadata\": {\n",
      "              \"input_tokens\": 32,\n",
      "              \"output_tokens\": 14,\n",
      "              \"total_tokens\": 46,\n",
      "              \"input_token_details\": {\n",
      "                \"audio\": 0,\n",
      "                \"cache_read\": 0\n",
      "              },\n",
      "              \"output_token_details\": {\n",
      "                \"audio\": 0,\n",
      "                \"reasoning\": 0\n",
      "              }\n",
      "            },\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        },\n",
      "        \"text\": \"A soma de 1 + 1 é igual a 2.\"\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"completion_tokens\": 14,\n",
      "      \"prompt_tokens\": 32,\n",
      "      \"total_tokens\": 46,\n",
      "      \"completion_tokens_details\": {\n",
      "        \"accepted_prediction_tokens\": 0,\n",
      "        \"audio_tokens\": 0,\n",
      "        \"reasoning_tokens\": 0,\n",
      "        \"rejected_prediction_tokens\": 0\n",
      "      },\n",
      "      \"prompt_tokens_details\": {\n",
      "        \"audio_tokens\": 0,\n",
      "        \"cached_tokens\": 0\n",
      "      }\n",
      "    },\n",
      "    \"model_name\": \"gpt-3.5-turbo-0125\",\n",
      "    \"system_fingerprint\": null\n",
      "  },\n",
      "  \"run\": null,\n",
      "  \"type\": \"LLMResult\"\n",
      "}\n",
      "CPU times: total: 62.5 ms\n",
      "Wall time: 2.2 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='A soma de 1 + 1 é igual a 2.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 32, 'total_tokens': 46, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run--b0075ab6-f081-4aec-b88d-d7b3dfc9cca6-0', usage_metadata={'input_tokens': 32, 'output_tokens': 14, 'total_tokens': 46, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "chat.invoke(mensagens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4825361",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
